{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo Parquet\n",
    "ruta_archivo_parquet = r'C:\\Users\\guard\\OneDrive\\Desktop\\Henry Data Science\\Proyecto-FInal\\Datos\\gm_rev_NJNY_202502182030.parquet'\n",
    "\n",
    "# Leer el archivo Parquet en un DataFrame\n",
    "df = pd.read_parquet(ruta_archivo_parquet)\n",
    "\n",
    "# Asegurarnos de que no hay valores nulos en la columna 'text'\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "# Inicializar el analizador de sentimientos VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Definir una función para calcular la puntuación de sentimientos\n",
    "def analizar_sentimiento(texto):\n",
    "    if texto is None:\n",
    "        texto = \"\"  # Reemplazar valores nulos con cadena vacía\n",
    "    sentimientos = analyzer.polarity_scores(texto)\n",
    "    return sentimientos['compound']\n",
    "\n",
    "# Aplicar la función a la columna 'text' para obtener la puntuación de sentimientos\n",
    "df['sentimiento_puntuacion'] = df['text'].apply(analizar_sentimiento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna 'sentimiento' con valores categóricos basado en la puntuación de sentimientos\n",
    "df['sentimiento'] = df['sentimiento_puntuacion'].apply(lambda x: 'positivo' if x > 0 else 'negativo' if x < 0 else 'neutro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución inicial de clases: Counter({'positivo': 61102, 'negativo': 6636, 'neutro': 4862})\n",
      "Distribución después de SMOTE: Counter({'positivo': 61102, 'negativo': 61102, 'neutro': 61102})\n"
     ]
    }
   ],
   "source": [
    "# Mostrar la distribución inicial de clases\n",
    "print(\"Distribución inicial de clases:\", Counter(y_train))\n",
    "\n",
    "# Aplicar SMOTE para realizar el sobremuestreo\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Mostrar la nueva distribución de clases\n",
    "print(\"Distribución después de SMOTE:\", Counter(y_train_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Definir los parámetros de la cuadrícula\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],  # Normas de penalización L1 y L2\n",
    "    'solver': ['liblinear']  # Solvers compatibles con L1 y L2\n",
    "}\n",
    "\n",
    "# Inicializar el modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Configurar la búsqueda en cuadrícula\n",
    "grid_search = GridSearchCV(estimator=modelo, param_grid=param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "\n",
    "# Entrenar el modelo con la búsqueda en cuadrícula\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Obtener los mejores parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores parámetros:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.61      0.76      0.68      1633\n",
      "      neutro       0.72      0.81      0.77      1130\n",
      "    positivo       0.97      0.94      0.95     15387\n",
      "\n",
      "    accuracy                           0.91     18150\n",
      "   macro avg       0.77      0.84      0.80     18150\n",
      "weighted avg       0.92      0.91      0.92     18150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo con los mejores parámetros\n",
    "modelo_final = LogisticRegression(**best_params)\n",
    "modelo_final.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluar el modelo final\n",
    "y_pred = modelo_final.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizador_tfidf.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el modelo final y el vectorizador\n",
    "joblib.dump(modelo_final, 'modelo_sentimientos_final.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizador_tfidf.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
