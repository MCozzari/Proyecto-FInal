{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PT12 - Proyecto final - Grupo 2\n",
    "Una notebook para todo. </br>\n",
    "##### Transformaciones\n",
    "gm_sitios:</br>\n",
    "- columna 'address' queda en columnas separadas: domicilio como numero y calle, ciudad, esatdo y zip code </br>\n",
    "- Columna 'hours' la separa en columnas (Monday, Tuesday ... Sunday) con el horario de cada dia\n",
    "- Columna 'price' reemplazar '₩', '₩₩' por $ o $$ - esta forma de hacerlo debe ser muy lenta\n",
    "- Columna 'MISC' como variables dummies. De la columna:</br>\n",
    "    - Service options >> 'Delivery', 'Takeout', 'Dine-in'</br>\n",
    "    - Amenities >> kids </br>\n",
    "    - Atmosphere >> casual </br>\n",
    "    - Popular for >> 'Lunch', 'Dinner'</br>\n",
    "\n",
    "gm_reviews:\n",
    "- columna 'time' esta en ms. La convierte a datetime para obtener fecha de la review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import os\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leo el archivo parquet datos crudos\n",
    "# How to read a Parquet file into Pandas DataFrame?\n",
    "gm_sitios = pd.read_parquet(\"datos/gm_raw_parquet/gm_sitios_raw.parquet\" , engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos columnas que no serán utilizadas\n",
    "# NO ELIMINO 'price', 'MISC', PUEDE SERVIR PARA LAS RECOMENDACIONES\n",
    "# Por ahora conservo latitude y longitude porque puede servirnos para mostrar locales en el dashboard\n",
    "\n",
    "gm_sitios = gm_sitios.drop(columns=['description', 'state', 'relative_results', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecciono las filas que tienen pizza restaurant\n",
    "# df_mt_sitios_pizza = df_mt_sitios[df_mt_sitios['category'].apply(lambda x: 'Pizza restaurant' in x)]\n",
    "# TypeError: argument of type 'NoneType' is not iterable\n",
    "\n",
    "gm_sitios_pizza = gm_sitios[gm_sitios['category'].apply(lambda x: isinstance(x, list) and 'Pizza restaurant' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract state (two uppercase letters) using regex\n",
    "gm_sitios_pizza['state'] = gm_sitios_pizza['address'].str.extract(r',\\s*([A-Z]{2})\\s*\\d{5}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecciono las pizzerias de NJ y NY\n",
    "gm_sitios_pizza_NJNY = gm_sitios_pizza[gm_sitios_pizza['state'].isin(['NJ', 'NY'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en algunas direcciones dice ', United States' al final / Remove ', United States' if present\n",
    "gm_sitios_pizza_NJNY['cleaned_address'] = [addr.replace(\", United States\", \"\") for addr in gm_sitios_pizza_NJNY['address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex pattern to extract street address, city, and ZIP code\n",
    "pattern_1 = r'(?P<street_address_temp>.+),\\s*(?P<city>[^,]+),\\s*[A-Z]{2}\\s*(?P<zip_code>\\d{5})$'\n",
    "\n",
    "# Aplicar regex a la columna 'address'\n",
    "df_extracted = gm_sitios_pizza_NJNY['cleaned_address'].str.extract(pattern_1)\n",
    "\n",
    "# Combinar con el DataFrame original\n",
    "gm_sitios_pizza_NJNY = gm_sitios_pizza_NJNY.join(df_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To capture only the part to the right of the comma\n",
    "gm_sitios_pizza_NJNY[\"street_address\"] = gm_sitios_pizza_NJNY[\"street_address_temp\"].str.split(\",\", n=1).str[1].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimino las columnas que ya no usamos\n",
    "# df.drop(['Column1', 'Columns2'], axis=1)\n",
    "gm_sitios_pizza_NJNY.drop(['address', 'cleaned_address', 'street_address_temp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimino los duplicados manteniendo la primera instancia\n",
    "gm_sitios_pizza_NJNY.drop_duplicates(subset=['gmap_id'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary format para extraer los horarios por dia de cada local. La columna es una lista de listas\n",
    "gm_sitios_pizza_NJNY['hours_dict'] = gm_sitios_pizza_NJNY['hours'].apply(lambda x: dict(x) if isinstance(x, list) else {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand 'hours_dict' into separate columns (one per day)\n",
    "hours_expanded = gm_sitios_pizza_NJNY['hours_dict'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge expanded columns back into original DataFrame\n",
    "gm_sitios_pizza_NJNY = pd.concat([gm_sitios_pizza_NJNY, hours_expanded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazar '₩', '₩₩' por $ o $$ - esta forma de hacerlo debe ser muy lenta\n",
    "#replacements = str.maketrans({\"h\": \"H\", \"e\": \"E\", \"o\": \"O\"})\n",
    "#res = s.translate(replacements)\n",
    "# string keys in translate table must be of length 1\n",
    "#gm_sitios_pizza_NJNY['price'] = (\n",
    "#    gm_sitios_pizza_NJNY['price']\n",
    "#    .str.replace(\"₩₩\", \"$$\", regex=False)  # Primero reemplaza ₩₩ por $$\n",
    "#    .str.replace(\"₩\", \"$\", regex=False)    # Luego reemplaza ₩ por $\n",
    "#)\n",
    "gm_sitios_pizza_NJNY['price'] = gm_sitios_pizza_NJNY['price'].replace({'₩': '$', '₩₩': '$$'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completo con un diccionario vacios las filas que tienen la columna MISC en NaN\n",
    "gm_sitios_pizza_NJNY['MISC'] = gm_sitios_pizza_NJNY['MISC'].apply(lambda x: {} if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand 'MISC' into separate columns (one per iem)\n",
    "MISC_expanded = gm_sitios_pizza_NJNY['MISC'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimino aca las columnas que no usare\n",
    "MISC_expanded.drop(['Offerings', 'Dining options', 'Health & safety', 'Accessibility', 'Crowd', 'Planning', \n",
    "'Payments', 'Highlights', 'From the business', 'Health and safety'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge expanded columns back into original DataFrame\n",
    "# creo que se concatena por los indices. Por eso no necesita que haya una columna en comun\n",
    "gm_sitios_pizza_NJNY = pd.concat([gm_sitios_pizza_NJNY, MISC_expanded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['Column1', 'Columns2'], axis=1)\n",
    "# elimino columnas que ya no necesito\n",
    "gm_sitios_pizza_NJNY.drop(['category', 'MISC', 'hours', 'hours_dict'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNAS DUMMIES\n",
    "\n",
    "# Apply function to filter only \"Lunch\" and \"Dinner\" and join them as a string\n",
    "# Handle NaN values and apply filtering\n",
    "#gm_sitios_pizza_NJNY['Service options'] = gm_sitios_pizza_NJNY['Service options'].apply(\n",
    "#    lambda x: ', '.join([item for item in x if item in ['Delivery', 'Takeout', 'Dine-in']]) \n",
    "#    if isinstance(x, list) else ''\n",
    "#)\n",
    "gm_sitios_pizza_NJNY['Service options'] = gm_sitios_pizza_NJNY['Service options'].apply(\n",
    "    lambda x: ','.join([item for item in x if item in ['Delivery', 'Takeout', 'Dine-in']]) \n",
    "    if isinstance(x, list) else ''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to filter only \"good for kids\" and join them as a string\n",
    "# Handle NaN values and apply filtering\n",
    "gm_sitios_pizza_NJNY['Amenities'] = gm_sitios_pizza_NJNY['Amenities'].apply(\n",
    "    lambda x: 'Good for kids' if isinstance(x, list) and 'Good for kids' in x else ''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to Atmosphere to filter only \"casual\" and join them as a string\n",
    "# Handle NaN values and apply filtering\n",
    "gm_sitios_pizza_NJNY['Atmosphere'] = gm_sitios_pizza_NJNY['Atmosphere'].apply(\n",
    "    lambda x: 'Casual' if isinstance(x, list) and 'Casual' in x else ''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to filter only \"Lunch\" and \"Dinner\" and join them as a string\n",
    "# Handle NaN values and apply filtering\n",
    "gm_sitios_pizza_NJNY['Popular for'] = gm_sitios_pizza_NJNY['Popular for'].apply(\n",
    "    lambda x: ','.join([item for item in x if item in ['Lunch', 'Dinner']]) \n",
    "    if isinstance(x, list) else ''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar get_dummies() para convertir en variables dummies\n",
    "df_dummies_serv = gm_sitios_pizza_NJNY['Service options'].str.get_dummies(sep=',')\n",
    "df_dummies_am = gm_sitios_pizza_NJNY['Amenities'].str.get_dummies(sep=',')\n",
    "df_dummies_at = gm_sitios_pizza_NJNY['Atmosphere'].str.get_dummies(sep=',')\n",
    "df_dummies_pop = gm_sitios_pizza_NJNY['Popular for'].str.get_dummies(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['Column1', 'Columns2'], axis=1)\n",
    "# elimino columnas que ya no necesito\n",
    "gm_sitios_pizza_NJNY.drop(['Service options', 'Amenities', 'Atmosphere', 'Popular for'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames along columns\n",
    "gm_sitios_pizza_NJNY = pd.concat([gm_sitios_pizza_NJNY, df_dummies_serv, df_dummies_am, df_dummies_at, df_dummies_pop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leo los datasets de reviews completos\n",
    "df_rev_NJ = pd.read_parquet('datos/gm_raw_parquet/gm_review_NJ_raw.parquet' , engine='fastparquet')\n",
    "df_rev_NY = pd.read_parquet('datos/gm_raw_parquet/gm_review_NY_raw.parquet' , engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos, por ahora, name, pics y resp. no usaremos esas columnas\n",
    "df_rev_NJ = df_rev_NJ.drop(columns=['name', 'pics', 'resp'])\n",
    "df_rev_NY = df_rev_NY.drop(columns=['name', 'pics', 'resp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar los duplicados manteniendo la primera instancia\n",
    "df_rev_NJ = df_rev_NJ.drop_duplicates(subset=['user_id', 'gmap_id', 'time'], keep='first')\n",
    "df_rev_NY = df_rev_NY.drop_duplicates(subset=['user_id', 'gmap_id', 'time'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir columna time en int64 a datetime\n",
    "df_rev_NJ['date'] = pd.to_datetime(df_rev_NJ['time'], unit='ms')\n",
    "df_rev_NY['date'] = pd.to_datetime(df_rev_NY['time'], unit='ms')\n",
    "\n",
    "# Eliminamos la columan time\n",
    "df_rev_NJ = df_rev_NJ.drop(columns=['time'])\n",
    "df_rev_NY = df_rev_NY.drop(columns=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uno los dataframes de reviews hacer join con el dataframe de sitios /\n",
    "# asi solo conservare los locales para los que haya reviews y las reviews para las que conozcamos los locales\n",
    "df_rev_NJNY = pd.concat([df_rev_NJ, df_rev_NY], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge entre los dos dataframe . Luego guardare solo los que tengan datos en ambos.\n",
    "gm_NJNY = pd.merge(gm_sitios_pizza_NJNY, df_rev_NJNY, how='inner', on='gmap_id') # tengo que hacer inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vuelvo a separar los archivos para dejarlos listos para la base de datos\n",
    "# unique_age_city = df[['Age', 'City']].drop_duplicates()\n",
    "gm_sitios_NJNY = gm_NJNY[['gmap_id', 'name', 'street_address', 'city', 'state', 'zip_code',   'latitude','longitude','avg_rating','num_of_reviews','price',\n",
    "                   'Monday','Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'Delivery', 'Dine-in', 'Takeout', 'Good for kids', 'Casual', \n",
    "                   'Dinner', 'Lunch']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora selecciono las reviews\n",
    "gm_rev_NJNY = gm_NJNY[['gmap_id', 'user_id', 'date', 'rating' , 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes listos para cargar en las tablas de la base de datos </br>\n",
    "La siguiente celda, donde grabo los archivos, no es necesaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardo gm_sitios_NJNY\n",
    "gm_sitios_NJNY.to_parquet('datos/gm_raw_parquet/gm_sitios_NJNY_202502190828.parquet' , engine='fastparquet')\n",
    "\n",
    "# guardo gm_rev_NJNY\n",
    "#gm_rev_NJNY.to_parquet('datos/gm_raw_parquet/gm_rev_NJNY_202502182030.parquet' , engine='fastparquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
